# 深度学习入门

## 全景图

![https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-07-29-deeplearnging.png](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-07-29-deeplearnging.png)

## 深度学习解释

假设深度学习要处理的信息是“⽔流”，⽽处理数据的深度学习⽹络是⼀个由管道和阀⻔组
成的巨⼤⽔管⽹络。⽹络的⼊⼝是若⼲管道开⼝，⽹络的出⼝也是若⼲管道开⼝。这个⽔
管⽹络有许多层，每⼀层由许多个可以控制⽔流流向与流量的调节阀。根据不同任务的需
要，⽔管⽹络的层数、每层的调节阀数量可以有不同的变化组合。对复杂任务来说，调节
阀的总数可以成千上万甚⾄更多。⽔管⽹络中，每⼀层的每个调节阀都通过⽔管与下⼀层
的所有调节阀连接起来，组成⼀个从前到后，逐层完全连通的⽔流系统。

## 传统机器学习和深度学习的相识点

他们都可能对数据进⾏⼀些操作：

- 数据清洗
- 数据标签
- 归⼀化
- 去噪
- 降维

**核心区别**

- 传统机器学习的特征提取主要依赖⼈⼯，针对特定简单任务的时候⼈⼯提取特征会简单有
效，但是并不能通⽤。
- 深度学习的特征提取并不依靠⼈⼯，⽽是机器⾃动提取的。这也是为什么⼤家都说深度学
习的可解释性很差，因为有时候深度学习虽然能有好的表现，但是我们并不知道他的原理
是什么。

## 卷积神经网络 - CNN

价值:

1. 能够将⼤数据量的图⽚有效的降维成⼩数据量(并不影响结果)
2. 能够保留图⽚的特征，类似⼈类的视觉原理

基本原理:

1. 卷积层 – 主要作⽤是保留图⽚的特征
2. 池化层 – 主要作⽤是把数据降维，可以有效的避免过拟合
3. 全连接层 – 根据不同任务输出我们想要的结果

实际应用:

1. 图⽚分类、检索
2. ⽬标定位检测
3. ⽬标分割
4. ⼈脸识别
5. ⻣骼识别

卷积神经⽹络 – CNN 最擅⻓的就是图⽚的处理。它受到⼈类视觉神经系统的启发。

### 卷积—提取特征

![Untitled](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%20e72756bebdce4dd89e2ed7e7e9577924/Untitled.png)

这个过程我们可以理解为我们使⽤⼀个过滤器（卷积核）来过滤图像的各个⼩区域，从⽽
得到这些⼩区域的特征值。

在具体应⽤中，往往有多个卷积核，可以认为，每个卷积核代表了⼀种图像模式，如果某
个图像块与此卷积核卷积出的值⼤，则认为此图像块⼗分接近于此卷积核。如果我们设计
了6个卷积核，可以理解：我们认为这个图像上有6种底层纹理模式，也就是我们⽤6中基
础模式就能描绘出⼀副图像。

**总结：卷积层的通过卷积核的过滤提取出图⽚中局部的特征，跟上⾯提到的⼈类视觉的特**

**征提取类似。**

### 池化 — 数据降维，避免过拟合

![Untitled](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%20e72756bebdce4dd89e2ed7e7e9577924/Untitled%201.png)

上图中，我们可以看到，原始图⽚是20×20的，我们对其进⾏下采样，采样窗⼝为

10×10，最终将其下采样成为⼀个2×2⼤⼩的特征图。

之所以这么做的原因，是因为即使做完了卷积，图像仍然很⼤（因为卷积核⽐较⼩），所

以为了降低数据维度，就进⾏下采样。

**总结：池化层相⽐卷积层可以更有效的降低数据维度，这么做不但可以⼤⼤减少运算量，**

**还可以有效的避免过拟合。**

### 全连接层 — 输出结果

经过卷积层和池化层降维过的数据，全连接层才能”跑得动”，不然数据量太⼤，计算成本
⾼，效率低下。

## 循环神经网络-RNN

RNN 是⼀种能有效的处理序列数据的算法。⽐如：⽂章内容、语⾳⾳频、股票价格⾛势…
之所以他能处理序列数据，是因为在序列中前⾯的输⼊也会影响到后⾯的输出，相当于有
了“记忆功能”。但是 RNN 存在严重的短期记忆问题，⻓期的数据影响很⼩（哪怕他是重
要的信息）。

于是基于 RNN 出现了 LSTM 和 GRU 等变种算法。这些变种算法主要有⼏个特点：

1. ⻓期信息可以有效的保留
2. 挑选重要信息保留，不重要的信息会选择“遗忘”

典型应用:

1. ⽂本⽣成
2. 语⾳识别
3. 机器翻译
4. ⽣成图像描述
5. 视频标记

### RNN基本原理

传统神经⽹络的结构⽐较简单：输⼊层 – 隐藏层 – 输出层。

RNN 跟传统神经⽹络最⼤的区别在于每次都会将前⼀次的输出结果，带到下⼀次的隐藏层
中，⼀起训练。如下图所示：

![Untitled](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%20e72756bebdce4dd89e2ed7e7e9577924/Untitled%202.png)

**RNN 到 LSTM – ⻓短期记忆⽹络**

RNN 是⼀种死板的逻辑，越晚的输⼊影响越⼤，越早的输⼊影响越⼩，且⽆法改变这个逻
辑。

LSTM 做的最⼤的改变就是打破了这个死板的逻辑，⽽改⽤了⼀套灵活了逻辑——只保留
重要的信息。

**从 LSTM 到 GRU - Gated Recurrent Unit**

GRU 是 LSTM 的⼀个变体。他保留了 LSTM 划重点，遗忘不重要信息的特点，在long-term 传播的时候也不会被丢失。

![Untitled](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%20e72756bebdce4dd89e2ed7e7e9577924/Untitled%203.png)

GRU 主要是在 LSTM 的模型上做了⼀些简化和调整，在训练数据集⽐较⼤的情况下可以节
省很多时间。

## LSTM - 长短期记忆网络

所有递归神经⽹络都具有神经⽹络的链式重复模块。在标准的 RNN 中，这个重复模块具
有⾮常简单的结构，例如只有单个 tanh 层。

![Untitled](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%20e72756bebdce4dd89e2ed7e7e9577924/Untitled%204.png)

LSTM 也具有这种类似的链式结构，但重复模块具有不同的结构。不是⼀个单独的神经⽹
络层，⽽是四个，并且以⾮常特殊的⽅式进⾏交互。

![Untitled](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%20e72756bebdce4dd89e2ed7e7e9577924/Untitled%205.png)

[](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)

## 生成对抗网络-GAN

生成对抗网络（Generative Adversarial Networks，GAN）是深度学习中一种流行的无监督学习算法，由Ian Goodfellow等人于2014年提出。GAN包含一个生成器（Generator）和一个判别器（Discriminator），两者通过博弈论的方式共同训练，以达到生成真实数据的目的。

具体地说，生成器的目标是生成与真实数据相似的合成数据，而判别器则需要将合成数据与真实数据区分开来。GAN的核心思想是让生成器不断生成数据样本，通过判别器对其进行判别，不断更新生成器的参数，使得生成器的输出能够愈发逼近真实数据分布。同时，判别器也需要不断优化自己的参数，使得能够更加准确地区分真实数据和合成数据。

## 深度强化学习

深度强化学习（Deep Reinforcement Learning，DRL）是指将深度学习与强化学习相结合的一种机器学习方法。强化学习是一种从环境中学习行为的方法，其目标是通过最大化累计奖励来学习与环境的交互策略。深度学习则是一种基于神经网络的机器学习方法，可以自动从数据中学习到高层次的特征表示。

在深度强化学习中，一个智能体需要通过与环境的交互来学习到一个最优策略，使得在该策略下获得的累计奖励最大化。智能体的策略可以由一个深度神经网络来表示，称为策略网络（Policy Network）。策略网络将当前的状态作为输入，输出在该状态下采取各种行动的概率分布，然后从中随机选择一个行动进行执行。

在学习过程中，智能体需要不断地与环境进行交互，根据采取的行动和得到的奖励来调整策略网络的参数，以使得累计奖励最大化。为了提高学习效率，通常还会使用一种价值函数（Value Function）来评估状态的价值，以指导策略网络的优化方向。价值函数可以由另一个深度神经网络来表示，称为价值网络（Value Network）。