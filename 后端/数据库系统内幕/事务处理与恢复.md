# 事务处理与恢复

在之前的文章中，重点介绍了数据库的存储结构B树，现在开始介绍负责缓冲区管理、锁管理和恢复的更高层的组件，这是理解数据库事务的前提。

事务是指数据库中一个不可分的逻辑工作单元,允许将多个操作表示为一个步骤。数据库事务必须遵循ACID。

- A(Atomicity):  原子性, 事务中的步骤要么全部执行成功、要么全部执行失败
- C(Consistency):  一致性, 事务只能将数据库从一个有效状态带到另外一个有效状态，并保持所有的数据库不变量(比如约束、引用完整性)，这是最弱的属性，是唯一一个有用户去控制而不是数据库自身去保证的属性.
- I(Isolation):  隔离性, 多个并发执行的事务应该能够互不干扰地运行。但是由于性能原因，许多数据库使用的隔离级别要比这个定义弱，一个事务所做的更改可能对其他并发事务可见或不可见。
- D(Durability):  持久性， 一旦事务被提交，所有的数据库状态都必须被持久化到磁盘上，即使发生断电、系统故障或崩溃也不受影响。

事务除了在磁盘上保存和组织存储结构之外，还需要多个组件协同工作，比如在节点内部：

1. 事务管理器负责协调、调度和跟踪事务以及事务的各个步骤
2. 锁管理器可保护对资源的访问，并防止那些可能破坏数据完整性的并发访问。
3. 页缓存充当持久化存储和存储引擎其余部分之间的中介。它将状态更改暂存在内存中，同时也用于缓存那些尚未与持久化存储同步的页。
4. 日志管理器记录了应用在缓存页上的操作，这些操作还没和持久化存储同步，而日志可以确保这些操作不会在崩溃时丢失。
5. 分布式(多分区)事务需要额外的协调机制以及远程执行。

## 一、缓冲区管理

大多数数据库都采用双层存储体系： 较慢的磁盘和较快的内存。为了减少对磁盘的访问，页面被缓存在内存中，当存储层再次请求该页时，将返回其缓存副本。

将未缓存的页从磁盘加载进来的过程叫做换入(page in)。缓存的页一旦被更改过就成了脏页，直到这些更改被刷写(flush)到磁盘上。

由于页缓存的内存区通常比整个数据集小得多，所以页缓存终究会被填满。为了换入新的页，必须将其中某个页换出(evict)缓存.

![Untitled](%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%E4%B8%8E%E6%81%A2%E5%A4%8D%20d90c24215f3e4c78a318118e8e8118dc/Untitled.png)

总结页缓存的主要功能:

- 在内存中保留被缓存的页的内容
- 把对磁盘页的修改缓冲起来，并且修改的是缓存的版本
- 当被请求的页不在内存中且可用空间足够时，页缓存会将其换入并返回缓存的版本
- 如果请求的页在缓存中，则直接返回缓存的版本。
- 如果可用空间不足以放下新的页，则某些其他页会被换出，被换出的页的内容会被
刷写回磁盘。

**1、缓存语义**

页缓存是对磁盘访问的抽象，并将逻辑写操作与物理写操作分离。如果想让页缓存不要换出某些页，则可以将它们固定(pin)住。如果某个页被修改了，就会被标记为脏页，该标志位就表示和磁盘内容不同步，必须刷写到磁盘才能保证持久性。

**2、缓存回收**

如果页的内容与磁盘是同步的（已刷写过或从未修改过），井且该页面未被固定或引用，则可以立即将其换出 。脏页则必须在刷写之后才能换出。如果页正在披其他线程使用．则不能将其换出。

如果每次换出页都刷写磁盘，则其性能可能会很差。因此某些数据库使用单独的后 台进
程，该进程循环检查可能披换出的脏页，更新其磁盘上的版本。

另一个要记住的重要属性是持久性: 如果数据库崩溃，则所有未刷写的数据都会丢失。为了确保所有更改都被持久化，检查点进程会协调刷写进程。检查点进程控制预写日志(WAL) 和页缓存，并确保两者协同工作。只有当缓存页完成刷写之后，相关操作的日志记录才能从 WAL 中丢弃。在上述过程完成后才能将脏页换出缓存

这意味着需要在多个目标间做一些权衡：
• 推迟刷写以减少磁盘访问次数。
• 提早刷写以让页能被快速地换出。
• 选择要换出的页，并以最优的顺序刷写。
• 将缓存大小保持在其内存池范围内。
• 避免因数据没有被持久化到主存储中而丢失它们。

**3、在缓存中锁定页**

每次读取或写入都进行磁盘IO是不切实际的：并发的读取可能会请求同一页，并发的写入也可能会修改同一页。由于 树越靠近顶部越”窄”,所以层次较高的节点（靠近根的节点）在大多数读取中都会披命中。分裂与合并操作最终也会传播到较高层次的节点。这总味着至少树的某一部分一定会受益于缓存。

那么我们就可以 ”锁定”那些近期大概率会被用到的页，来帮助减少磁盘访问次数并提高性能。

**4、页置换**

当缓存容量用完时，为了加载新页，必须换出旧页。但是，除非我们换出近期不太可能再次访问的页．否则这些页可能会反复加载多次一一我们原本可以将它们始终放在内存中。为了优化该行为，我们需要找到一种方法来估计后续页被访问的可能性。

为此 我们应当根据换出策略（有时也称为页置换策略）将页换出，该策略尝试找出近期最不可能被再次访问的页。当这个页披换出后，新页可以加载到它的位置上。

**FIFO和IRU**

最简单的页置换策略是先进先出 (FIFO) FIFO 按插入顺序维护一个页 ID 的队列，将新页添加到队列尾部。每当页缓存已满时， FIFO 从队列头部取出元素，这也就是最早披换入的页。由于它不考虑后续的页访问，而是仅考虑页换入时间，所以该策略对于大多数真实系统而言是不切实际的。例如，根节点和最上层节点的页最先被换入，根据此算法，这些页也会被最先换出缓存，尽管从树结构中能明显看出这些页很快就会被再次换入．

一个对 FIFO 算法的自然扩展是最长时间未使用策略 (LRU) [TANENBAUM14]。LRU也按插人顺序维护一个换出候选队列，但是当我们重复访问某个页时， LRU 会将其放回队列尾部，就像首次换入时那样。然而，并发坏境下每次访问都要更新引用和重新链接节点可能代价较高。

此外还有一些基于LRU的缓存换出策略。例如， 2Q （双队列 LRU) 维护两个队列 ，在初次访问时放入第一个队列，在后续访问时将它们移入第二个热队列，从而区分最近访问的页和经常访问的页 [J ONSON94] U-K 通过跟踪最近的K次访问来识别频繁用的页，并使用此信息来估计访问时间。

**Clock**

在某些情况下，效率可能比精度更重要。 CLOCK 算法变体常常被用作 LRU的一种更加紧凑、更加缓存友好且并发性更好的替代品。

CLOCK-sweep 算法将页的引用和与之关联的访问位保存在环形缓冲区中。一些变体使用计数器而不是比特位来描述频率。每当访问某个页面时，都将它的访问位设置为1。CLOCK算法的工作原理是循环检查环形缓冲区上的访问位：

- 如果访问位为1且该页未被引用，则将其置为0并检查下一页。
- 如果访问位已经为0， 则将该页作为一个要换出的候选，井安排在后续将其换出。
- 如果页当前正被引用，则它的访问位保持不变。算法假定披访问页的访问位不可为0，因此不会被换出缓存，这使得被引用的页更不可能被置换。

![Untitled](%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%E4%B8%8E%E6%81%A2%E5%A4%8D%20d90c24215f3e4c78a318118e8e8118dc/Untitled%201.png)

使用环状缓冲区的一个优点是：时钟指针和缓冲区内容都可以用比较－置换 CAS原子操作来修改，无须额外的加锁机制。该算法很容易理解和实现，常被用于教科书[TANENBAUM 4] 和真实系统中。

LRU 并非对于所有数据库来说都是最佳的置换策略。有时考虑使用频率而非最近使用时间作为预测因子可能更贴合实际。最后，对于负载很重的数据库系统，最近使用时间可能不太具有参考性，因为它只表示项目被访问的顺序。

**LFU**

TinyLFU 是一种基于频率的页置换策略，它正是这样做的： TinyLFU 不根据页换入的时间来换出页，而是根据使用频率对页进行排序。

TinyLFU使用频率直方图 ORMOD l] 来维护一个紧凑的缓存访问历史记录，因为出于实用性考虑，保存完整历史记录的代价太高。
元素可能位于以下三个队列中的某一个：
• 入场 (admissio 队列 维护新加入的元素，用 LRU 策略实现。
• 考察 (probation) 队列：其中的元素最有可能被换出缓存。
• 保护 (protected) 队列 其中的元素将在队列中保留更长的时间。
TinyLFU 不是选择要换出哪些元素，而是选择要保留的元素。访问频率相对较高的元素会被晋升到考察队列中。在后续访问中，元素可以从考察队列移至保护队列。如果保护队列已满，则必须将其中某个元素放回考察队列。经常访问的元素有较高的机会被保护，而不经常访问的元素则更有可能袚换出缓存。

![Untitled](%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%E4%B8%8E%E6%81%A2%E5%A4%8D%20d90c24215f3e4c78a318118e8e8118dc/Untitled%202.png)

## 二、恢复

数据库系统构建在硬件层及软件层之上 ，而这些硬件和软件自身可能存在稳定性和可靠性问题。无论是数据库系统本身还是面 的软件和硬件组件都有可能会发生故陓。数据库实现者必须考虑这些故障场景，并确保已经承诺的数据确实已经写人了。

预写日志 (Write-Ahead Log, WAL 也称为提交日志）是一种仅追加的辅助磁盘数据结构，用于崩溃和事务的恢复 。页缓存允许我们在内存中缓冲对页面内容的更改，而在将缓存的内容刷写回磁盘之前， WAL是保留操作历史唯一磁盘副本。许多数据库系统使用仅追加的预写日志，例如PostgreSQL和MySQL。
预写日志的主要功能可以概括为:
• 在允许页缓存将页上的修改缓存起来的同时，保证数据库系统仍然具有持久性语义。
• 在那些受操作影响的缓存页被同步到磁盘上之前，将所有操作持久化到磁盘上。每个修改数据库状态的操作必须先写日志到磁盘上，然后才能修改相关页的内容。
• 当发生崩溃时，使系统可以从操作日志中重建内存中丢失的更改

除此以外，预写日志在事务处理中也起着重要作用。它确保将数据存储到持久性存储中，即使发生崩溃也依然可用： 通过重放日志便可恢复未提交的数据，这样数据库就可以完全恢复到崩溃前的状态。在本节中 ，我们会经常提到ARIES (Algorithm for Recovery and Isolation Exploiting Semantics, 用语义的恢复和隔离算法），这是种先进的、被广泛使用和引用的算法。

**1、日志语义**

WAL 由日志记录组成，每条记录都有一个唯一的、单调递增的日志序列 (LSN )。通常， LSN由一个内部的计数器或时间戳表示。由于日志记录不一定占据整个磁盘块，所以其内容会被缓存在日志缓冲区中，并在强制刷盘 (force) 操作时披刷写到磁盘上。强制刷盘操作发生在日志缓冲区被填满时， 也可能被来自事务管理器或页缓存的请求所触发。各日志记录必须以 LSN 的顺序刷写到磁盘上。

系统在回滚或恢复期间也有可能发生崩溃，为了确保这种情况下系统能继续正常工作，某些系统会在撤销橾作时记录补偿日志记录 (CLR) 并将其存储在日志中。

**2、操作日志与数据日志**

一些数据库系统，使用影子页，一种写时复制 (co y-on-w ite) 技术来确保数据持久性和事务原子性。新内容被存放在一个新的、未发布的影子页中，并通过指针翻转使其可见，从 旧页切换到包含更新内容的新页。

任何状态变化都可以由前像(before-image) 和后像 (after-image) 或相应的重做 (redo)和撤销 undo) 操作表示。对前像应用重做操作会生成后像，类似地、对后像应用撤销操作会产生一个前像。

我们可以使用物理日志（保存对完整页状态或字节级的更改）或逻辑日志（保存在当前状态上执行的操作）将数据记录或页从一个状态变成另一个状态，无论是正向还是逆向。

在实践中，许多数据库结合使用上述两种方法：使用逻辑日志记录执行撤销操作（以提升并发），使用物理日志记录执行重做操作（以缩短恢复时间。

**3、steal和force策略**

- steal策略: 在事务提交之前允许刷写事务修改过的页.
- no-steal策略: 不允许将未提交的事务内容刷写到磁盘。
- force策略: 在事务提交前将事务修改的所有贞刷写到磁盘上.
- no-force: 即使事务修改的某些页尚未刷写到磁盘上，该事务也可以提交

直到事务提交前，我们需要保存有足够的信息来撤销它的结果。如果事务中涉及的页都已经刷写到磁盘，那么我们需要在日志中保留撤销信息，以在事务提交之前确保它能披回滚；否则，我们必须保留重做日志。在这两种情况下，只有当撤销或重做记录披写人日志文件后，事务才能提交。

当数据库崩溃后重启时，恢复过程分为 个阶段：
1、 分析阶段识别出页缓存中的脏页以及崩溃时正在进行的事务。脏页的信息用于标识重做阶段的起点。进行中事务的清单用于在撤销阶段中回滚未完成的事务。
2.、重做阶段重放历史记录直到崩溃点，井将数据库恢复到先前的状态。此阶段会处理未完成的事务以及那些已提交但尚未将修改刷写到持久化存储的事务。
3 、撤销阶段回滚所有未完成的事务，并将数据库还原到最后的一致状态。所有操作均按反向时间顺序回滚。为了防止数据库在恢复过程中再次崩溃，撤销事务所做的操作也会袚记录到日志中，以避免重复应用。

## 三、并发控制

并发控制是一组用于处理并发事务间交互的技术，这些技术可以大致分为以下几类:

- 乐观并发控制（OCC）
    - 当多个事务执行并发读取或写入操作，事务不会彼此阻塞，而是保留其操作历史，并在提交前检查这些历史操作是否存在冲突的可能。如果冲突则可能中止其中某一个冲突的事务。
- 多版本并发控制(MVCC)
    - 允许一条记录同时存在多个时间戳的版本，通过该方式并发事务读到的是数据库过去某个时刻的一致视图。MVCC可以使用验证技术来实现，即只允许多个更新或事务提交中的某一个获胜，也可以使用无锁技术(时间戳排序)或基于锁(两阶段锁)的技术。
- 悲观并发控制(PCC)
    - PCC既有基于锁的实现，也有不加锁的实现。基于锁的实现要求事务维护数据库记录上的锁，以防止其他事务修改或访问当前记录，知道锁释放为止。不加锁的实现根据未完成事务的调度，维护读取与写入的操作列表以限制事务的执行。

**1、可串行化**

如果一个调度中的事务完全独立且无交错地执行，则我们称它为串行的调度：每个事务在下个事务开始之前已完全执行。相比于多个事务的各种交错执行，串行执行很容易进行论证

**2、事务隔离**

隔离级别指定了事务的各部分如何以及何时可以被其他事务看到。换句话说，隔离级别描述了将事务与其他并发事务隔离的程度，以及执行过程中可能发生哪些种类的异常.

**3、读异常和写异常**

在执行井发事务期间可能发生的读异常：脏读、不重复读和幻读。

- 脏读 (dirty read) 是指一个事务能读到其他事务未提交的更改.
- 不可重复读 (non repeatable read, 有时也称为模糊读 (fuzzy read) ），是指同一事务两次
查询同一行却得到不同的结果
- 幻读是指事务两次查询同样的行集合却得到不同的结果。它与不可重复读类似，但仅适用于范围查询。

写异常: 丢失更新，脏写和写偏斜

- 丢失更新 (lost update) 发生在事务T1和T2同时尝试更新V值时，假设都允许两者提交，那么最终会有一个事务更新的值会被丢弃.
- 脏写 (dirty write) 指的是某个事务拿到了一个未提交的值（即脏读）．对其进行修改井保存。换句话说，事务结果来自从未提交过的值。
- 写偏针 (write skew) 是指各个单独的事务都赴守要求的约束，但它们的组合却违反这些约束。例如，事务T1和T2修改两个账户 A1 和A2的值。最初 A1 100 元， A2 150 元。账户的值可以负，只要两个账户之和为非负数就行，即要满足 A1 + A2 ≥ 0。T1和T2分别尝试从A1和A2取出 200 元。在两个事务开始时， A1 + A2 = 250元，因此共有 50 元可用。两个事务都认为它们没有违反约束，可以提交。提交后， A1为－ 100 元， A2为-50 元，这显然违反了账户之和为非负数的要求。

**4、隔离级别**

![Untitled](%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%E4%B8%8E%E6%81%A2%E5%A4%8D%20d90c24215f3e4c78a318118e8e8118dc/Untitled%203.png)

一些数据库使用快照隔离 (snapshot isolation) 。在快照隔离中，一个事务可以观察到所有在该事务开始前已提交的事务所做的状态更改。每个事务都会获取一个数据快照，并在快照上执行查询。 快照在事务执行期间不会发生变化。只有当事务中修改的值没有被其他事务修改时，才可以提交事务，否则它将被中止并回滚。

快照隔离中可能发生写偏斜异常: 如果两个事务分别读取本地状态、修改不同的记录并遵守本地的约束，则两者都可以提交。

**5、乐观并发控制**

一般来说，事务执行分为三个阶段:

- 读阶段
    - 事务在其私有上下文中执行各步骤，此时一切更改都对其他事务不可见。在该步骤完成后，我们就知道了事务的所有依赖条件(读集合)，以及事务会产生的所有副作用(写集合).
- 验证阶段
    - 检查并发事务的读集合和写集合，查看其操作之间是否存在可能违反可序列化性质的冲突。如果事务读取的某些数据现在已过期，或者事务的写入将覆盖在其读阶段提交的事务所写入的某些值，则清除事务的私有上下文、重启读阶段。换句话说，验证阶段确定提交事务是否遵守 ACID 性质。
- 写阶段
    - 如果验证阶段未发现任何冲突，则事务可以将其写集合从私有上下文提交到数据库状态中。
    

后向式并发控制确保任意一对事务T1和 T2 都具有以下性质：

- 如果T1在T2的读阶段开始之前提交，则T1可以提交
- 如果T1在T2的写阶段之前提交，则T1的写集合与T2的读集合不相交。换句话说，T1不能看到任何T2看到的值。
- 如果T1的读阶段在T2的读阶段之前完成 ，则T2的写集合与T1的读或写集合均不相交。换句话说，两个事务操作独立的数据集合，此两者都可以提交。

乐观并发仍然具有临界区，所以同一时刻只能进入一个事务。要让某些操作具有非排他性的所有权，另一条途径是使用读写锁(读时共享访问)。

**6、多版本并发控制**

多版本并发控制是数据库中实现事务一致性的一种方法，它允许记录存在多个版本，并使用单调递增的事务 ID 或时间戳。这使得读写操作在存储层面上只需要最小限度的协调，因为读操作可以继续访问旧的值，直到新的值被提交。

**7、悲观并发控制**

在事务运行时确定其间的冲突并阻塞或中止执行。

时间戳排序是最简单的悲观（无锁）并发控制方案之一， 其中每个 事务都有一个时间戳，事务操作能否执行取决于是否已经提交过时间戳更晚的事务。为了实现这一点，事务管理器需要维护每个值的 max_read_timestamp和max_write _timestamp, 它们分别描述了并发事务执行的读和写操作。

**8、基于锁的并发控制**

基于锁的并发控制方案是悲观并发控制的一种形式，它对数据库对象显式地加锁，不是用时间戳排序之类的协议来制定操作顺序。使用锁的缺点包括锁竞争和扩展性问题。

使用最广泛的基于锁的技术之一就是两阶段锁(2PL), 它将锁管理分为两个阶段:

- 增长阶段： 此阶段将获取事务所需锁，并且不释放任何锁
- 收缩阶段： 此阶段释放增长阶段获得的所有锁。

![Untitled](%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%E4%B8%8E%E6%81%A2%E5%A4%8D%20d90c24215f3e4c78a318118e8e8118dc/Untitled%204.png)

最简单的处理死锁的方法是引人超时机制并中止长时间运行的事务，假定它们可能处于死锁状态。另 一种策略，即保守 2PL, 要求事务在执行任何橾作之前先获取所有锁，如果做不到就中止事务。但是，这些方法极大地限制了系统的并发，因此数据库系统大多使用事务管理器来检测或避免（或者说防止）死锁。

死锁检测通常是用等待图 (waits-for graph) 实现的，等待图跟踪进行中的事务间的关系，并建立其间的等待关系。

**锁与闩锁的区别**

锁与闩锁的区别在于，锁通常用于隔离重叠的事务、管理数据库内容，而闩锁通常用于控制对共享内存区域的并发访问，比如叶子节点等内存区域。

**闩锁耦合**

加闩锁最直接的方法是获取从根到目标叶节点途中的所有闩锁。这会导致并发性能瓶颈，而且在大多数情况下可以避免。

闩锁耦合是一种非常简单的方法：它允许持有门锁的时间更短，并在当前操作明显不再需要它们时立即释放。

- 在读取路径上，一旦找到子节点并获得它的闩锁，就可以释放父节点的闩锁。
- 插入时，如果能保证操作不会引起能传播到当前节点的结构变化，那么就可以释放父节点的闩锁。
- 删除时，如果操作不会导致合并，那么就可以释放父节点上的闩锁。